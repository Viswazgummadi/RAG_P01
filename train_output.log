nohup: ignoring input
Loading and preparing dataset...
Loading model: mistralai/Mistral-7B-Instruct-v0.2
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]
Setting up LoRA for efficient fine-tuning...
Tokenizing dataset...
Map:   0%|          | 0/5713 [00:00<?, ? examples/s]Map:  18%|█▊        | 1000/5713 [00:00<00:04, 1139.47 examples/s]Map:  35%|███▌      | 2000/5713 [00:01<00:02, 1381.46 examples/s]Map:  53%|█████▎    | 3000/5713 [00:02<00:01, 1479.48 examples/s]Map:  70%|███████   | 4000/5713 [00:02<00:01, 1565.64 examples/s]Map:  88%|████████▊ | 5000/5713 [00:03<00:00, 1627.74 examples/s]Map: 100%|██████████| 5713/5713 [00:03<00:00, 1564.45 examples/s]Map: 100%|██████████| 5713/5713 [00:03<00:00, 1514.97 examples/s]
Starting training...
  0%|          | 0/1071 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/export/home/kote/miniconda3/envs/rag_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
  0%|          | 1/1071 [00:14<4:18:32, 14.50s/it]  0%|          | 2/1071 [00:28<4:14:37, 14.29s/it]  0%|          | 3/1071 [00:42<4:13:25, 14.24s/it]  0%|          | 4/1071 [00:57<4:12:51, 14.22s/it]  0%|          | 5/1071 [01:11<4:12:32, 14.21s/it]  1%|          | 6/1071 [01:25<4:12:20, 14.22s/it]  1%|          | 7/1071 [01:39<4:12:05, 14.22s/it]  1%|          | 8/1071 [01:53<4:11:56, 14.22s/it]  1%|          | 9/1071 [02:08<4:11:51, 14.23s/it]  1%|          | 10/1071 [02:22<4:11:44, 14.24s/it]                                                     1%|          | 10/1071 [02:22<4:11:44, 14.24s/it]  1%|          | 11/1071 [02:36<4:11:37, 14.24s/it]  1%|          | 12/1071 [02:50<4:11:25, 14.24s/it]